# ğŸ–¼ï¸ WikiArt Style Classification â€” CNN Deep Learning Project

![Python](https://img.shields.io/badge/Python-3.10-blue)
![TensorFlow](https://img.shields.io/badge/TensorFlow-2.14-orange)
![Keras](https://img.shields.io/badge/Keras-2.14-red)
![License](https://img.shields.io/badge/License-MIT-green)

Projet de **classification des styles artistiques** du dataset WikiArt Ã  l'aide d'un **CNN (Convolutional Neural Network)**.

---

## ğŸ“Œ Objectif du projet
- DÃ©velopper un modÃ¨le CNN capable de reconnaÃ®tre diffÃ©rents **styles artistiques** (impressionnisme, cubisme, surrÃ©alismeâ€¦).  
- PrÃ©processing automatique, augmentation de donnÃ©es et entraÃ®nement pour des performances optimales.

---

## ğŸ—‚ï¸ Structure du projet
WikiArt-CNN/
â”‚â”€â”€ README.md # Documentation
â”‚â”€â”€ CNN_wikiArt.ipynb # Notebook principal
â”‚â”€â”€ dataset/ # Images organisÃ©es par style
â”‚â”€â”€ models/ # ModÃ¨les sauvegardÃ©s (.h5)
â”‚â”€â”€ results/ # Courbes, matrices, prÃ©dictions
â”‚â”€â”€ requirements.txt # DÃ©pendances Python

yaml
Copier le code

---

## ğŸ§  ModÃ¨le & Architecture
- 2 blocs **Conv2D + MaxPooling2D**  
- **Dropout** pour rÃ©duire lâ€™overfitting  
- Flatten â†’ Dense â†’ Softmax  
- Optimizer : **Adam (lr=0.0001)**  
- Loss : **Categorical Crossentropy**

**RÃ©sumÃ© architecture :**
Conv2D (32 filtres)
MaxPooling
Dropout (0.25)
Conv2D (64 filtres)
MaxPooling
Flatten
Dense(128)
Dense(output_classes, activation='softmax')

yaml
Copier le code

---

## ğŸ–¼ï¸ Dataset WikiArt
- Contient plusieurs milliers dâ€™Å“uvres classÃ©es par **style artistique**  
- PrÃ©traitement : redimensionnement (128Ã—128), normalisation (/255), augmentation (rotation, zoom, flip, shift)

**Exemples de classes :**
![Impressionnisme](results/impressionism.jpg) ![Cubisme](results/cubism.jpg) ![SurrÃ©alisme](results/surrealism.jpg)

---

## âš™ï¸ PrÃ©paration des donnÃ©es
```python
from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=30,
    zoom_range=0.15,
    horizontal_flip=True,
    validation_split=0.2
)

train_data = train_datagen.flow_from_directory(
    'dataset/',
    target_size=(128,128),
    batch_size=32,
    class_mode='categorical',
    subset='training'
)

val_data = train_datagen.flow_from_directory(
    'dataset/',
    target_size=(128,128),
    batch_size=32,
    class_mode='categorical',
    subset='validation'
)
ğŸš€ EntraÃ®nement du modÃ¨le
python
Copier le code
from tensorflow.keras.callbacks import ModelCheckpoint

checkpoint = ModelCheckpoint(
    'models/best_model.h5',
    monitor='val_accuracy',
    save_best_only=True,
    verbose=1
)

history = model.fit(
    train_data,
    validation_data=val_data,
    epochs=30,
    callbacks=[checkpoint]
)
Exemple de progression :

makefile
Copier le code
Epoch 8/30
accuracy: 0.6395 - loss: 0.9641
val_accuracy: 0.6198 - val_loss: 1.0365
ğŸ“Š RÃ©sultats & Performances
Accuracy entraÃ®nement : ~65â€“70%

Accuracy validation : ~60%

Courbes et matrices de confusion disponibles dans results/

ğŸ§ª Exemple d'infÃ©rence
python
Copier le code
from tensorflow.keras.preprocessing import image
import numpy as np

img = image.load_img("test.jpg", target_size=(128,128))
img_array = np.expand_dims(np.array(img)/255.0, axis=0)

pred = model.predict(img_array)
print("Predicted style:", class_names[np.argmax(pred)])
ğŸ“¦ Installation & ExÃ©cution
1ï¸âƒ£ Cloner le projet :

bash
Copier le code
git clone https://github.com/Imen-SA/CNN_WikiArt.git
cd CNN_WikiArt
2ï¸âƒ£ Installer les dÃ©pendances :

bash
Copier le code
pip install -r requirements.txt
3ï¸âƒ£ Lancer le notebook :

bash
Copier le code
jupyter notebook CNN_wikiArt.ipynb
ğŸ“ Licence
MIT License

ğŸ”— Liens
GitHub : https://github.com/Imen-SA/CNN_WikiArt