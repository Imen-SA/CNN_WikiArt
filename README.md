üñºÔ∏è WikiArt Style Classification ‚Äî CNN Deep Learning Project

Projet de classification des styles artistiques du dataset WikiArt √† l'aide d'un CNN (Convolutional Neural Network).

üìå Objectif du projet

Le but est de d√©velopper un mod√®le CNN capable de reconna√Ætre et de classer diff√©rentes cat√©gories de styles artistiques (impressionnisme, cubisme, surr√©alisme, etc.) √† partir des images d'≈ìuvres du dataset WikiArt.

Le pipeline inclut :

Le pr√©traitement des donn√©es brutes.

L'application de l'augmentation de donn√©es pour la robustesse du mod√®le.

L'entra√Ænement d'un mod√®le pour des performances de classification optimales.

üóÇÔ∏è Structure du projet

WikiArt-CNN/
‚îÇ
‚îú‚îÄ‚îÄ README.md           # Documentation principale
‚îú‚îÄ‚îÄ CNN_wikiArt.ipynb   # Notebook principal contenant le code d'entra√Ænement
‚îú‚îÄ‚îÄ dataset/            # Dossier contenant les images, organis√©es par style (classe)
‚îú‚îÄ‚îÄ models/             # Dossier pour les mod√®les sauvegard√©s (.h5)
‚îú‚îÄ‚îÄ results/            # Dossier pour les courbes de performance, matrices de confusion et exemples
‚îî‚îÄ‚îÄ requirements.txt    # Liste des d√©pendances Python


üß† Mod√®le & Architecture

Le mod√®le est un r√©seau de neurones convolutif s√©quentiel con√ßu pour extraire des caract√©ristiques visuelles complexes sp√©cifiques aux styles artistiques.

R√©sum√© de l'Architecture

Couche

Description

Sortie (Exemple)

Input

Image 128x128x3

(None, 128, 128, 3)

Conv2D

32 filtres, ReLU

(None, 128, 128, 32)

MaxPooling2D

R√©duction de taille

(None, 64, 64, 32)

Dropout

Taux de 25% (r√©gularisation)

-

Conv2D

64 filtres, ReLU

(None, 64, 64, 64)

MaxPooling2D

R√©duction de taille

(None, 32, 32, 64)

Flatten

Aplatissement des donn√©es

(None, 65536)

Dense

128 neurones, ReLU

(None, 128)

Dense

output_classes neurones, Softmax

(None, N_CLASSES)

Configuration de l'Entra√Ænement

Optimizer : Adam (avec un taux d'apprentissage recommand√© de lr=0.0001).

Loss Function : Categorical Crossentropy (adapt√©e pour la classification multi-classes).

üñºÔ∏è Dataset WikiArt

Le dataset est compos√© de plusieurs milliers d‚Äô≈ìuvres d'art class√©es selon leur style.

Pr√©traitement

Les images sont pr√©trait√©es de la mani√®re suivante :

Redimensionnement : (128 √ó 128 pixels).

Normalisation : Mise √† l'√©chelle des valeurs de pixels (division par 255.0).

Augmentation de Donn√©es : Pour am√©liorer la robustesse et g√©n√©raliser le mod√®le.

Transformation

Param√®tres

Rescale

1./255

Rotation

30 degr√©s max

Zoom

0.15 max

Flip

Horizontal

Exemples de Classes

Les exemples ci-dessous montrent la diversit√© des styles g√©r√©s par le mod√®le.
| Style | Image |
| :--- | :--- |
| Impressionnisme |  |
| Cubisme |  |
| Surr√©alisme |  |

‚öôÔ∏è Pr√©paration des donn√©es (Code)

Le code suivant utilise ImageDataGenerator pour charger les donn√©es, appliquer l'augmentation et cr√©er les g√©n√©rateurs d'entra√Ænement et de validation.

from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=30,
    zoom_range=0.15,
    horizontal_flip=True,
    validation_split=0.2 # 20% des donn√©es pour la validation
)

train_data = train_datagen.flow_from_directory(
    'dataset/',
    target_size=(128,128),
    batch_size=32,
    class_mode='categorical',
    subset='training'
)

val_data = train_datagen.flow_from_directory(
    'dataset/',
    target_size=(128,128),
    batch_size=32,
    class_mode='categorical',
    subset='validation'
)


üöÄ Entra√Ænement du mod√®le (Code)

Le mod√®le est entra√Æn√© sur 30 √©poques avec un m√©canisme de ModelCheckpoint pour sauvegarder automatiquement le meilleur mod√®le bas√© sur la pr√©cision de la validation (val_accuracy).

from tensorflow.keras.callbacks import ModelCheckpoint

# Sauvegarde uniquement le mod√®le le plus performant
checkpoint = ModelCheckpoint(
    'models/best_model.h5',
    monitor='val_accuracy',
    save_best_only=True,
    verbose=1
)

history = model.fit(
    train_data,
    validation_data=val_data,
    epochs=30,
    callbacks=[checkpoint]
)


Exemple de Progression

Epoch 8/30
accuracy: 0.6395 - loss: 0.9641
val_accuracy: 0.6198 - val_loss: 1.0365


üìä R√©sultats & Performances

Accuracy Entra√Ænement : ~65‚Äì70%

Accuracy Validation : ~60%

Les courbes de perte (Loss) et de pr√©cision (Accuracy), ainsi que la matrice de confusion, sont disponibles dans le dossier results/.

üß™ Exemple d'inf√©rence (Pr√©diction)

Comment utiliser le mod√®le sauvegard√© (best_model.h5) pour pr√©dire le style d'une nouvelle ≈ìuvre :

from tensorflow.keras.preprocessing import image
import numpy as np

# 1. Charger et pr√©traiter l'image
img = image.load_img("test.jpg", target_size=(128,128))
# 2. Convertir en tableau numpy, normaliser et ajouter la dimension du batch
img_array = np.expand_dims(np.array(img)/255.0, axis=0) 

# 3. Pr√©diction
pred = model.predict(img_array)

# 4. Afficher le r√©sultat
# (Assurez-vous que 'class_names' est d√©fini et correspond aux index du g√©n√©rateur)
# Exemple: class_names = list(train_data.class_indices.keys())
print("Predicted style:", class_names[np.argmax(pred)])


üì¶ Installation & Ex√©cution

Suivez ces √©tapes pour cloner le projet et lancer le notebook.

1Ô∏è‚É£ Cloner le projet :

git clone [https://github.com/Imen-SA/CNN_WikiArt.git](https://github.com/Imen-SA/CNN_WikiArt.git)
cd CNN_WikiArt


2Ô∏è‚É£ Installer les d√©pendances :

pip install -r requirements.txt


3Ô∏è‚É£ Lancer le notebook :

jupyter notebook CNN_wikiArt.ipynb


üìù Licence

Ce projet est distribu√© sous la Licence MIT.

üîó Liens

GitHub : https://github.com/Imen-SA/CNN_WikiArt